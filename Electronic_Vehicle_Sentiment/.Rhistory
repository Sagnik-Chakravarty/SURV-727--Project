library(RedditExtractoR)
# Types of EV are:
# BEV: Battery Electric Vehicle,
# PHEV: Plug in Hybrid Electric Vehicle
# HEV: Hybrid Electric Vehicle
keywords <- c('BEV',
'PHEV',
'HEV',
'Battery Electric Vehicle',
'Plug in Hybrid Electric Vehicle',
'Hybrid Electric Vehicle',
'environment',
'battery',
'fuel',
'gas',
'sustainability',
'sustainable',
'pollution',
'autonomous')
reddit_url <- function(x, keyword = keywords){
ls <- list()
n <- length(keyword)
for (i in 1:n) {
df <- data.frame(find_thread_urls(keyword[i],
sort_by = 'top',
subreddit = x,
period = 'all'))
ls[[i]] <- df
}
Sys.sleep(5)
return(ls)
}
teslamotors <- reddit_url(subreddit[1])
library(jsonlite)
write_json(teslamotors, "Teslamotors_URL.json", pretty = TRUE)
saveRDS(teslamotors, "Teslamotors_url.rds")
fuckcars <- reddit_url(subreddit[2])
write_json(fuckcars, "fuckcars_URL.json", pretty = TRUE)
saveRDS(fuckcars, "fuckcars_url.rds")
electricvehicles <- reddit_url(subreddit[3])
write_json(electricvehicles, "electricvehicles.json", pretty = TRUE)
saveRDS(electricvehicles, "electricvehicles.rds")
teslamodel3 <- reddit_url(subreddit[4])
write_json(teslamodel3, "teslamodel3.json", pretty = TRUE)
saveRDS(teslamodel3, "teslamodel3.rds")
rivian <- reddit_url(subreddit[5])
write_json(rivian, "Rivian.json", pretty = TRUE)
saveRDS(rivian, "Rivian.rds")
teslamotors <- readRDS("Teslamotors_url.rds")
fuckcars <- readRDS("fuckcars_url.rds")
electricvehicles <- readRDS("electricvehicles.rds")
teslamodel3 <- readRDS("teslamodel3.rds")
rivian <- readRDS("Rivian.rds")
keywords <- c('BEV',
'PHEV',
'HEV',
'Battery Electric Vehicle',
'Plug in Hybrid Electric Vehicle',
'Hybrid Electric Vehicle',
'environment',
'battery',
'fuel',
'gas',
'sustainability',
'sustainable',
'pollution',
'autonomous')
teslamotors_df1 <- create_keyword_dataframe(teslamotors)
View(teslamotors_df)
View(teslamotors_df1)
fuckcars_df1 <- create_keyword_dataframe(fuckcars)
electricvehicles_df1 <- create_keyword_dataframe(electricvehicles)
electricvehicles_df1 <- create_keyword_dataframe(electricvehicles)
teslamodel3_df1 <- create_keyword_dataframe(teslamodel3)
rivian1 <- create_keyword_dataframe(rivian)
rivian_df1 <- create_keyword_dataframe(rivian)
electricvehicles <- reddit_url(subreddit[3])
write_json(electricvehicles, "electricvehicles.json", pretty = TRUE)
saveRDS(electricvehicles, "electricvehicles.rds")
electricvehicles_df1 <- create_keyword_dataframe(electricvehicles)
gc()
teslamotors <- readRDS("Teslamotors_url.rds")
fuckcars <- readRDS("fuckcars_url.rds")
electricvehicles <- readRDS("electricvehicles.rds")
teslamodel3 <- readRDS("teslamodel3.rds")
rivian <- readRDS("Rivian.rds")
keywords <- c('BEV',
'PHEV',
'HEV',
'Battery Electric Vehicle',
'Plug in Hybrid Electric Vehicle',
'Hybrid Electric Vehicle',
'environment',
'battery',
'fuel',
'gas',
'sustainability',
'sustainable',
'pollution',
'autonomous')
create_keyword_dataframe <- function(result_list){
names(result_list) <- keywords
df <- data.frame()
for(i in names(result_list)){
if(nrow(result_list[[i]])>0){
temp_df <- result_list[[i]]
temp_df$matched_keyword <- i
df <- rbind(df, temp_df)
}
}
df <- unique(df)
final_df <- aggregate(
matched_keyword ~ date_utc+ url+ text+ title+ comments,
data = df,
FUN = function(x) paste(unique(x), collapse = ",")
)
rm(result_list)
return(final_df)
}
teslamotors_df1 <- create_keyword_dataframe(teslamotors)
View(teslamotors_df1)
teslamotors_df <- teslamotors_df1
rm(teslamotors_df1)
fuckcars_df1 <- create_keyword_dataframe(fuckcars)
fuckcars_df <- create_keyword_dataframe(fuckcars)
rm(fuckcars_df1)
electricvehicles_df <- create_keyword_dataframe(electricvehicles)
teslamodel3_df <- create_keyword_dataframe(teslamodel3)
rivian_df <- create_keyword_dataframe(rivian)
rm(electricvehicles, teslamodel3, teslamotors, fuckcars, rivian)
library(tidytext)
library(dplyr)
library(stringr)
clean_text_df <- function(x){
n <- length(strsplit(x, "\n")[[1]])
tk <- tibble(line = 1:n, word = x)
tk <- tk %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
return(tolower(str_c(tk$word, collapse = ' ')))
}
teslamotors_df_cleaned <- teslamotors_df %>%
rowwise() %>%
mutate(cleaned_title = title, cleaned_text = text) %>%
select(-title, -text) %>%
ungroup()
View(teslamotors_df_cleaned)
teslamotors_df_cleaned <- teslamotors_df %>%
rowwise() %>%
mutate(cleaned_title = clean_text_df(title),
cleaned_text = clean_text_df(text)) %>%
select(-title, -text) %>%
ungroup()
teslamotors <- readRDS("Teslamotors_url.rds")
teslamotors_df <- create_keyword_dataframe(teslamotors)
teslamotors_df_cleaned <- teslamotors_df %>%
rowwise() %>%
mutate(cleaned_title = clean_text_df(title),
cleaned_text = clean_text_df(text)) %>%
select(-title, -text) %>%
ungroup()
library(tidytext)
library(dplyr)
library(stringr)
clean_text_df <- function(x) {
# Split by line breaks and create a tibble
tk <- tibble(line = 1:length(x), text = x)
# Tokenize the text and remove stop words
tk <- tk %>%
unnest_tokens(word, text) %>%
anti_join(stop_words, by = "word")
# Collapse the cleaned words into a single string
cleaned_text <- tolower(str_c(tk$word, collapse = ' '))
return(cleaned_text)
}
teslamotors_df_cleaned <- teslamotors_df %>%
rowwise() %>%
mutate(cleaned_title = clean_text_df(title),
cleaned_text = clean_text_df(text)) %>%
select(-title, -text) %>%
ungroup()
View(teslamotors_df_cleaned)
teslamotors_df <- teslamotors_df %>%
rowwise() %>%
mutate(cleaned_title = clean_text_df(title),
cleaned_text = clean_text_df(text)) %>%
select(-title, -text) %>%
ungroup()
rm(teslamotors_df_cleaned)
fuckcars_df <- fuckcars_df %>%
rowwise() %>%
mutate(cleaned_title = clean_text_df(title),
cleaned_text = clean_text_df(text)) %>%
select(-title, -text) %>%
ungroup()
electricvehicles_df <- electricvehicles_df %>%
rowwise() %>%
mutate(cleaned_title = clean_text_df(title),
cleaned_text = clean_text_df(text)) %>%
select(-title, -text) %>%
ungroup()
teslamodel3_df <- teslamodel3_df %>%
rowwise() %>%
mutate(cleaned_title = clean_text_df(title),
cleaned_text = clean_text_df(text)) %>%
select(-title, -text) %>%
ungroup()
rivian_df <- rivian_df %>%
rowwise() %>%
mutate(cleaned_title = clean_text_df(title),
cleaned_text = clean_text_df(text)) %>%
select(-title, -text) %>%
ungroup()
teslamotors_df$date_utc <- as.Date(teslamotors_df$date_utc)
fuckcars_df$date_utc <- as.Date(fuckcars_df$date_utc)
electricvehicles_df$date_utc <- as.Date(electricvehicles_df$date_utc)
teslamodel3_df$date_utc <- as.Date(teslamodel3_df$date_utc)
rivian_df$date_utc <- as.Date(rivian_df$date_utc)
rm(teslamotors)
2112+1546+968+1234+1687
sum(teslamotors_df$comments)
sum(teslamotors_df$comments)+sum(fuckcars_df$comments) + sum(teslamodel3_df$comments) + sum(electricvehicles_df$comments) + sum(rivian_df$comments)
write_csv(teslamotors_df, 'teslamotors.csv')
write_csv(fuckcars_df, 'fuckcars.csv')
write_csv(electricvehicles_df, 'electric_vehicles.csv')
write_csv(teslamodel3_df, 'teslamdel3.csv')
write_csv(rivian_df, 'rivian.csv')
teslamotors_df %>% filter(comments == 0) %>% select(url)
View(teslamotors_df %>% filter(comments == 0) %>% select(url))
source("~/.active-rstudio-document")
a <- teslamotors_df %>% filter(comments == 0) %>% select(url)
scrape_upvotes(a[1])
source("~/.active-rstudio-document")
scrape_upvotes_from_urls(a)
scrape_upvotes_from_urls(teslamotors_df$url)
get_sentiments('afinn')
install.packages('textdata')
library(textdata)
get_sentiments('afinn')
get_sentiments('nrc')
get_sentiments('loughran')
get_sentiments('bing')
get_sentiments('bing') %>% filter(word == 'fuck')
get_sentiments('bing') %>% filter(word == 'sex')
get_sentiments('bing') %>% filter(word == 'asshole')
get_sentiments('bing') %>% filter(word == 'ass')
get_sentiments('bing') %>% filter(word == 'boobs')
get_sentiments('bing') %>% filter(word == 'fuck')
get_sentiments('affin') %>% filter(word == 'fuck')
get_sentiments('afinn') %>% filter(word == 'fuck')
get_sentiments('afinn') %>% filter(word == 'ass')
get_sentiments('afinn') %>% filter(word == 'hole')
get_sentiments('afinn') %>% filter(word == 'shit')
get_sentiments('afinn') %>% filter(word == 'motherfucker')
get_sentiments('afinn') %>% filter(word == 'wow')
install.packages("gutenbergr")
library(gutenbergr)
gutenbergr::gutenberg_works('frankenstein')
?gutensberg_works
?gutenberg_works
gutenbergr::gutenberg_works(author = 'Dan Brown')
gutenbergr::gutenberg_works(author = 'Dante')
gutenbergr::gutenberg_works(author = 'Brown, Dan')
gutenbergr::gutenberg_works(author == 'Brown, Dan')
gutenbergr::gutenberg_works(author == 'william, defoe')
gutenbergr::gutenberg_works(author == 'Shelly, Mary')
gutenbergr::gutenberg_works(author == 'Shelley, Mary')
gutenbergr::gutenberg_works(author == 'Shakespeare, William')
library(janeaustenr)
tidy_books <- austen_books() %>%
group_by(books) %>%
mutate(
line_number = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup()
tidy_books <- austen_books() %>%
group_by(books) %>%
mutate(
line_number = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup()
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
line_number = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup()
tidy_books
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
line_number = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books
nrc <- get_sentiments('nrc')
nrc_joy <- get_sentiments('nrc') %>%
filter(sentiment == 'joy')
tidy_books %>%
filter(books == 'Sense & Sensibility') %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
tidy_books %>%
filter(book == 'Sense & Sensibility') %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
?pivot_wider
library(tidyr)
?pivot_wider
jane_austen_sent <- tidy_books %>%
inner_join(get_sentiments('bing')) %>%
count(book, index = line_number %?% 80, sentiment)
jane_austen_sent <- tidy_books %>%
inner_join(get_sentiments('bing')) %>%
count(book, index = line_number %/% 80, sentiment)
jane_austen_sent
jane_austen_sent <- tidy_books %>%
inner_join(get_sentiments('bing')) %>%
count(book, index = line_number %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
jane_austen_sent
jane_austen_sent <- tidy_books %>%
inner_join(get_sentiments('bing')) %>%
count(book, index = line_number %/% 80, sentiment) # %>%
jane_austen_sent
unique(jane_austen_sent$sentiment)
jane_austen_sent <- tidy_books %>%
inner_join(get_sentiments('bing')) %>%
count(book, index = line_number %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
unique(jane_austen_sent$sentiment)
jane_austen_sent
jane_austen_sent <- tidy_books %>%
inner_join(get_sentiments('nrc')) %>%
count(book, index = line_number %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
jane_austen_sent
get_sentiments('bing')
get_sentiments('bing') %>% filter(sentiment = 'positive')
get_sentiments('bing') %>% filter(sentiment == 'positive')
library(tidyr)
get_sentiments(teslamotors_df$cleaned_title)
get_sentiments <- function(x){
nrc <- get_sentiments('nrc')
affin <- get_sentiments('affin')
bing <- get_sentiments('bing')
tk <- tibble(line = 1:nrow(x), text = x)
tk <- tk %>%
unnest_tokens(word, text)
return(tk)
}
get_sentiments(teslamotors_df$cleaned_title)
options(expressions = 500000)  # Default is 5000
get_sentiments(teslamotors_df$cleaned_title)
get_sentiments(teslamotors_df$cleaned_title)
memory.limit(size = 16000)
ulimit -s 16384  # Adjust the number if necessary
?options
get_sentiments(teslamotors_df$cleaned_title)
st <- "My name is Sagnik"
st <- tibble(line = 1, word = st)
st %>% unnest_tokens(word, text)
st %>% unnest_tokens(word, st)
st %>% unnest_tokens(word, st)
st %>% unnest_tokens(word, text)
unnest_tokens()
?unnest_tokens
View(teslamodel3_df)
nrc <- get_sentiments('nrc')
affin <- get_sentiments('affin')
bing <- get_sentiments('bing')
get_sentiments <- function(data){
tk <- tibble(line = 1:nrow(data), text = data)
tk <- tk %>%
unnest_tokens(word, text) %>%
inner_join(nrc, by = 'word') %>%
count(line, sentiment, sort = TRUE) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0)
}
get_sentiments(teslamotors_df$cleaned_title)
teslamotors_df$cleaned_text
nrow(teslamotors_df$cleaned_text)
length(teslamotors_df$cleaned_text)
View(teslamotors_df)
get_sentiments <- function(data){
tk <- tibble(line = 1:length(data), text = data)
tk <- tk %>%
unnest_tokens(word, text) %>%
inner_join(nrc, by = 'word') %>%
count(line, sentiment, sort = TRUE) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0)
}
get_sentiments(teslamotors_df$cleaned_title)
get_sentiments <- function(data){
tk <- tibble(line = 1:length(data), text = data)
tk <- tk %>%
unnest_tokens(word, text) %>%
distinct(line, word) %>%
inner_join(nrc, by = 'word') %>%
count(line, sentiment, sort = TRUE) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0)
}
get_sentiments(teslamotors_df$cleaned_title)
get_sentiments <- function(data){
tk <- tibble(line = 1:length(data), text = data)
tk <- tk %>%
unnest_tokens(word, text) %>%
distinct(line, word) %>%
inner_join(nrc, by = 'word') %>%
count(line, sentiment, sort = TRUE) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment_nrc = positive - negative)
return(tk)
}
get_sentiments(teslamotors_df$cleaned_title)
get_sentiments(teslamotors_df$cleaned_title)
get_sentiments <- function(data){
tk <- tibble(line = 1:length(data), text = data)
tk <- tk %>%
unnest_tokens(word, text) %>%
inner_join(nrc, by = 'word') %>%
count(line, sentiment, sort = TRUE) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment_nrc = positive - negative)
return(tk$sentiment_nrc)
}
get_sentiments(teslamotors_df$cleaned_title)
affin <- get_sentiments('affin')
affin <- get_sentiments('affin')
?get_sentiments
afinn <- get_sentiments('afinn')
afinn <- get_sentiments('afinn')
rm(tidy_books, st, jane_austen_sent)
afinn <- get_sentiments('afinn')
get_sentiments('afinn')
get_sentiments('bing')
gc()
library(textdata)
library(tidyr)
afinn <- get_sentiments('afinn')
afinn <- get_sentiments('afinn')
library(readr)
teslamotors_df <- read_csv('teslamotors.csv')
teslamotors_df
library(tidytext)
library(dplyr)
library(stringr)
library(textdata)
nrow(teslamotors_df)
nrc <- get_sentiments('nrc')
afinn <- get_sentiments('afinn')
bing <- get_sentiments('bing')
teslamotors_df <- teslamotors_df
get_sentiments(teslamotors_df$cleaned_title)
get_sentiments(teslamotors_df$cleaned_title[1])
tk <- tk %>%
unnest_tokens(word, text) %>%
inner_join(get_sentiments('nrc')) %>%
count(line, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment_nrc = positive - negative)
get_sentiments <- function(x){
tk <- tibble(line = 1, text = x)
tk <- tk %>%
unnest_tokens(word, text) %>%
inner_join(get_sentiments('nrc')) %>%
count(line, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment_nrc = positive - negative)
return(tk)
}
get_sentiments(teslamotors_df$cleaned_title[1])
library(tidyr)
get_sentiments <- function(x){
tk <- tibble(line = 1, text = x)
tk <- tk %>%
unnest_tokens(word, text) %>%
inner_join(get_sentiments('nrc')) %>%
count(line, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment_nrc = positive - negative)
return(tk)
}
get_sentiments(teslamotors_df$cleaned_title[1])
teslamotors_df$cleaned_text[1]
a <- teslamotors_df$cleaned_text[1]
a
get_sentiments(a)
get_sentiments <- function(x){
tk <- tibble(line = 1:length(x), text = x)
tk <- tk %>%
unnest_tokens(word, text) %>%
inner_join(get_sentiments('nrc')) %>%
count(line, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment_nrc = positive - negative)
return(tk)
}
get_sentiments(teslamotors_df$cleaned_title[1])
get_sentiments(a)
