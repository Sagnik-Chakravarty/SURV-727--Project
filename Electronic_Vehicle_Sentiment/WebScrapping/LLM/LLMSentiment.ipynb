{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:13:25.191552Z",
     "start_time": "2024-12-03T23:13:25.158503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from groq import Groq\n",
    "\n",
    "api_key = \"Enter Your Api Key"\,
    "client = Groq(api_key=api_key)"
   ],
   "id": "db440b2f136671d6",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:13:31.323725Z",
     "start_time": "2024-12-03T23:13:29.613671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ],
   "id": "d6e9b8e8c8269ac9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models have become increasingly important in recent years, revolutionizing the field of natural language processing (NLP) and having a significant impact on various industries. Here are some reasons why fast language models are important:\n",
      "\n",
      "1. **Efficient computation**: Fast language models can process large amounts of text data quickly, making them ideal for applications where response time is critical. This is particularly important in areas like customer chatbots, where fast response times can improve user engagement and satisfaction.\n",
      "2. **Scalability**: As the amount of text data continues to grow, fast language models can handle the increased load, enabling applications to scale to meet the demands of large user bases.\n",
      "3. **Real-time processing**: Fast language models can process text in real-time, making them suitable for applications like sentiment analysis, entity recognition, and language translation, which require immediate processing and analysis of text data.\n",
      "4. **Improved performance**: Fast language models are designed to be more computationally efficient, which means they can be trained on larger datasets and perform better on complex NLP tasks, such as long-range dependencies and discourse-level processing.\n",
      "5. **Advancements in deep learning**: Fast language models have been instrumental in the development of deep learning algorithms, particularly in areas like attention mechanisms and transformer architectures. These advancements have opened up new possibilities for NLP applications.\n",
      "6. **Practical applications**: Fast language models have been integrated into various practical applications, such as:\n",
      "\t* Chatbots and voice assistants: providing fast and accurate responses to user queries.\n",
      "\t* Content analysis: enabling real-time analysis of large volumes of text data for sentiment analysis, topic modeling, and entity extraction.\n",
      "\t* Language translation: facilitating fast and accurate language translation, especially for applications like real-time communication and machine translation.\n",
      "\t* Question answering: enabling fast and accurate question answering systems, which are crucial in applications like search engines and expert systems.\n",
      "7. **Edge computing**: Fast language models can be deployed on edge devices, such as smartphones and smart home devices, enabling fast and efficient processing of text data at the edge, without relying on cloud-based services.\n",
      "8. **Healthcare and biotechnology**: Fast language models can be used to analyze large amounts of medical text data, such as electronic health records (EHRs), to improve patient outcomes, and to identify new patterns and trends in medical research.\n",
      "9. **Enhancing human-computer interaction**: Fast language models can improve the accuracy and efficiency of human-computer interaction by enabling natural language understanding and generation, which can lead to more effective and intuitive user interfaces.\n",
      "10. **Advancements in AI research**: Fast language models have sparked new research directions in AI, such as exploring the limits of language understanding, generating more coherent and realistic text, and developing more efficient algorithms for NLP tasks.\n",
      "\n",
      "In summary, fast language models have transformed the field of NLP, enabling efficient, scalable, and accurate processing of large amounts of text data, with significant implications for various industries and applications.\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:39:53.333732Z",
     "start_time": "2024-12-03T23:39:53.328894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_ids = [\n",
    "    \"Llama-3.1-70b-versatile\",\n",
    "    \"Llama-3.1-70b-specdec\",\n",
    "    \"Llama-3.1-8b-instant\",\n",
    "    \"Llama-3.2-1b-preview\",\n",
    "    \"Llama-3.2-3b-preview\",\n",
    "    \"Llama-3.2-11b-vision-preview\",\n",
    "    \"Llama-3.2-90b-vision-preview\",\n",
    "    \"Llama-guard-3-8b\",\n",
    "    \"Llama3-70b-8192\",\n",
    "    \"Llama3-8b-8192\",\n",
    "    \"Mixtral-8x7b-32768\",\n",
    "    \"whisper-large-v3\",\n",
    "    \"whisper-large-v3-turbo\"\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    \"What is your opinion on sustainability in terms of environmental impact and such of Electric vehicles?\",\n",
    "    \"What is your opinion on the different kinds of Electric Vehicles and which one do you think is the best in regards to sustainability and environment and Why?\",\n",
    "    \"What do you think is the long term better option when deciding between fuel and electric vehicles?\",\n",
    "    \"Overall is Electric Vehicle better compared to fuel?\"\n",
    "]\n",
    "\n",
    "personas = {\n",
    "    \"default\":\"You are an helpful assistant.\",\n",
    "    \"Redditor\":\"Respond as if you are a Reddit user\",\n",
    "    \"New York Times Reader\":\"Respond as if you are a daily reader of New York Times\"\n",
    "}"
   ],
   "id": "93ad51ffa8219b6c",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:30:16.612345Z",
     "start_time": "2024-12-03T23:30:16.584147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from groq import Groq\n",
    "\n",
    "api_key = \"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\"\n",
    "client = Groq(api_key=api_key)\n",
    "def groq_request(question, persona, model_id):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": persona},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        model = model_id,\n",
    "        max_tokens= 1024,\n",
    "        temperature= 0.5\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ],
   "id": "a7a56a916b4cbfb3",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:39:59.190187Z",
     "start_time": "2024-12-03T23:39:57.470353Z"
    }
   },
   "cell_type": "code",
   "source": "groq_request(questions[0], personas[\"Redditor\"], model_ids[0])",
   "id": "49283e37c5c2b8f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**u/EcoWarrior3000**\\n\\nI've been following the EV scene for a while now, and I've gotta say, it's a mixed bag when it comes to sustainability. On one hand, EVs are a huge improvement over traditional gas-guzzlers in terms of emissions. They produce zero tailpipe emissions, which is a major win for air quality and climate change.\\n\\nHowever, the production process for EVs is where things get a bit murky. The mining of lithium, cobalt, and other essential minerals for EV batteries has some serious environmental and social implications. For example, the Democratic Republic of Congo is a major supplier of cobalt, but the mining process has been linked to child labor and deforestation.\\n\\nAdditionally, the energy source used to generate the electricity that powers EVs is also a concern. If the energy is coming from fossil fuels, then the overall emissions savings of EVs are greatly reduced. But, if the energy is coming from renewable sources like solar or wind, then EVs can be a game-changer.\\n\\nThat being said, I still think EVs are a step in the right direction. As the technology continues to evolve, we're seeing more efficient batteries, reduced waste, and increased use of recycled materials. And, of course, there are some amazing companies out there that are prioritizing sustainability in their EV production processes.\\n\\n**TL;DR:** EVs are a mixed bag when it comes to sustainability, but they're still a step in the right direction. We need to focus on improving the production process, increasing the use of renewable energy, and reducing waste to make EVs a truly sustainable option.\\n\\n**Edit:** I just wanted to add that I'm not trying to bash EVs or discourage people from buying them. I just think it's essential to have a nuanced conversation about the environmental impact of EVs and work towards making them even more sustainable in the future.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:08:54.982061Z",
     "start_time": "2024-12-03T23:40:28.350627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "sleep_time = 10\n",
    "\n",
    "data = []\n",
    "for model_id in model_ids:\n",
    "    for question in questions:\n",
    "        for persona_name, persona in personas.items():\n",
    "            try:\n",
    "                # Get the response from the model\n",
    "                answer = groq_request(question, persona, model_id)\n",
    "                # Append the data to the list\n",
    "                data.append({\n",
    "                    \"Model\": model_id,\n",
    "                    \"Question\": question,\n",
    "                    \"Persona\": persona_name,\n",
    "                    \"Answer\": answer\n",
    "                })\n",
    "            except Exception as e:\n",
    "                # Handle any exceptions (e.g., API errors) and log them\n",
    "                data.append({\n",
    "                    \"Model\": model_id,\n",
    "                    \"Question\": question,\n",
    "                    \"Persona\": persona_name,\n",
    "                    \"Answer\": f\"Error: {str(e)}\"\n",
    "                })\n",
    "            # Sleep to avoid hitting rate limits\n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "df = pd.DataFrame(data)"
   ],
   "id": "e49ce5afc4f6fc8",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:18:07.426446Z",
     "start_time": "2024-12-04T00:18:07.412354Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv(\"/Users/sagnikchakravarty/Desktop/UMD_College_Work/Project/Electronic_Vehicle_Sentiment/WebScrapping/LLM/LLM_model.csv\", index=False, )",
   "id": "cd4d5bb3c458a102",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T01:58:12.985378Z",
     "start_time": "2024-12-04T01:58:12.971476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "error_models = df[df['Answer'].str.contains('Error:', na=False)]['Model'].unique()\n",
    "filtered_df = df[~df['Model'].isin(error_models)]"
   ],
   "id": "fae828f9475bf53d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m error_models \u001B[38;5;241m=\u001B[39m df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAnswer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mcontains(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError:\u001B[39m\u001B[38;5;124m'\u001B[39m, na\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\n\u001B[1;32m      2\u001B[0m filtered_df \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;241m~\u001B[39mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39misin(error_models)]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:23:12.150515Z",
     "start_time": "2024-12-04T00:23:12.143097Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_df.to_csv(\"/Users/sagnikchakravarty/Desktop/UMD_College_Work/Project/Electronic_Vehicle_Sentiment/WebScrapping/LLM/filtered_LLM_model.csv\", index=False, )",
   "id": "6ee1cd05cd23af3d",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:38:38.269362Z",
     "start_time": "2024-12-04T00:38:37.415630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "                      truncation = True)"
   ],
   "id": "c6388891742aaee0",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:40:00.741938Z",
     "start_time": "2024-12-04T00:40:00.730069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sentiment_analysis(text_series):\n",
    "  text_series = text_series.fillna(\"\").astype(str)\n",
    "  results = text_series.apply(lambda x: classifier(x)[0])\n",
    "  return results.apply(lambda result: (result['label'], result['score'])).tolist()"
   ],
   "id": "45264c594783a198",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:41:19.341018Z",
     "start_time": "2024-12-04T00:41:19.309717Z"
    }
   },
   "cell_type": "code",
   "source": "cleaned_llm = pd.read_csv(\"/Users/sagnikchakravarty/Desktop/UMD_College_Work/Project/Electronic_Vehicle_Sentiment/WebScrapping/LLM/cleaned_llm.csv\", index_col=0)",
   "id": "9a67d616919beb58",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:50:58.582688Z",
     "start_time": "2024-12-04T00:49:57.977687Z"
    }
   },
   "cell_type": "code",
   "source": "sentiment_answer = sentiment_analysis(cleaned_llm['cleaned_answer'])",
   "id": "76a3389d9a665555",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:54:40.265448Z",
     "start_time": "2024-12-04T00:54:40.256660Z"
    }
   },
   "cell_type": "code",
   "source": "cleaned_llm[['sentiment_title', 'sentiment_title_score']] = pd.DataFrame(sentiment_answer)",
   "id": "f24c798bb648a969",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:56:02.806452Z",
     "start_time": "2024-12-04T00:56:02.798057Z"
    }
   },
   "cell_type": "code",
   "source": "cleaned_llm.to_csv(\"/Users/sagnikchakravarty/Desktop/UMD_College_Work/Project/Electronic_Vehicle_Sentiment/WebScrapping/LLM/sentimentLLM.csv\", index=False)",
   "id": "d7f8a3fab6327598",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T01:58:02.104918Z",
     "start_time": "2024-12-04T01:58:01.923349Z"
    }
   },
   "cell_type": "code",
   "source": "error_models",
   "id": "253e14c933edbf16",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'error_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m error_models\n",
      "\u001B[0;31mNameError\u001B[0m: name 'error_models' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T02:36:49.349940Z",
     "start_time": "2024-12-06T02:36:49.313343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_order(new_item, current_order=[]):\n",
    "  current_order.append(new_item)\n",
    "  return current_order\n",
    "\n",
    "# First order, burger\n",
    "order1 = update_order({'item': 'burger', 'cost': '3.50'})\n",
    "\n",
    "# Second order, just a soda\n",
    "order2 = update_order({'item': 'soda', 'cost': '1.50'})\n",
    "\n",
    "# What's in that second order again?\n",
    "print(order2)"
   ],
   "id": "1139dd30b18525ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'item': 'burger', 'cost': '3.50'}, {'item': 'soda', 'cost': '1.50'}]\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
