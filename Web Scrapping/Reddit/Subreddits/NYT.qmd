```{r}
library(httr)
library(jsonlite)


api_key <- "WitNU2gMjn4URLzQTRgOxjVN0kWXZCAK"


keywords <- c('electric car', 'electric vehicle', 'ev', 'motor', 
              'car', 'battery', 'autonomous', 'tesla')

search_articles <- function(keyword, api_key) {
  base_url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json"
  
  query <- list(
    q = keyword,
    "api-key" = api_key
  )
  
  response <- GET(base_url, query = query)
  
  if (status_code(response) == 200) {
    content <- fromJSON(content(response, "text"), flatten = TRUE)
    return(content$response$docs)
  } else {
    warning(paste("Error for keyword:", keyword, "- Status code:", status_code(response)))
    return(NULL)
  }
}

results <- list()

for (keyword in keywords) {
  articles <- search_articles(keyword, api_key)
  if (!is.null(articles)) {
    results[[keyword]] <- articles
  }
  Sys.sleep(6)
}


for (keyword in names(results)) {
  cat("\nKeyword:", keyword, "\n")
  cat("Number of articles found:", nrow(results[[keyword]]), "\n")
  
  if (nrow(results[[keyword]]) > 0) {
    cat("First article headline:", results[[keyword]]$headline.main[1], "\n")
    cat("First article snippet:", results[[keyword]]$snippet[1], "\n")
  }
}
```

```{r}
library(dplyr)
library(tidyr)

# Convert results to a data frame
all_articles <- lapply(names(results), function(keyword) {
  if (!is.null(results[[keyword]]) && nrow(results[[keyword]]) > 0) {
    data.frame(
      keyword = keyword,
      headline = results[[keyword]]$headline.main,
      snippet = results[[keyword]]$snippet,
      word_count = results[[keyword]]$word_count,
      pub_date = as.Date(results[[keyword]]$pub_date)
    )
  }
}) %>% bind_rows()

# Check the structure of the consolidated data
head(all_articles)
```

```{r}
library(ggplot2)

article_counts <- all_articles %>%
  group_by(keyword) %>%
  summarise(article_count = n())

ggplot(article_counts, aes(x = reorder(keyword, -article_count), y = article_count, fill = keyword)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(title = "Number of Articles by Keyword",
       x = "Keyword",
       y = "Number of Articles") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
ggplot(all_articles, aes(x = pub_date, y = keyword, color = keyword)) +
  geom_point() +
  labs(title = "Publication Timeline by Keyword",
       x = "Publication Date",
       y = "Keyword") +
  theme_minimal()

```

```{r}
ggplot(all_articles, aes(x = keyword, y = word_count, fill = keyword)) +
  geom_boxplot(show.legend = FALSE) +
  labs(title = "Word Count Distribution by Keyword",
       x = "Keyword",
       y = "Word Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
library(wordcloud)
library(tm)

# Combine all headlines into a single text
headlines_text <- paste(all_articles$headline, collapse = " ")

# Create a word cloud
wordcloud(words = headlines_text,
          scale = c(3, 0.5),
          max.words = 100,
          random.order = FALSE,
          colors = brewer.pal(8, "Dark2"))

```


```{r}
library(tidyverse)
library(tidytext)
library(wordcloud)
library(lubridate)
library(gridExtra)
library(scales)
library(sentimentr)

# Convert results to dataframe
articles_df <- map_df(names(results), function(kw) {
  if (!is.null(results[[kw]])) {
    data.frame(
      keyword = kw,
      headline = results[[kw]]$headline.main,
      snippet = results[[kw]]$snippet,
      pub_date = as.Date(results[[kw]]$pub_date),
      section = results[[kw]]$section_name,
      stringsAsFactors = FALSE
    )
  }
})
```
```{r}
# 1. Keyword Frequency Plot
keyword_counts <- articles_df %>%
  count(keyword) %>%
  ggplot(aes(x = reorder(keyword, n), y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Number of Articles by Keyword",
       x = "Keyword",
       y = "Number of Articles") +
  theme_minimal()
```
```{r}
# 2. Timeline Plot
timeline_plot <- articles_df %>%
  ggplot(aes(x = pub_date, fill = keyword)) +
  geom_histogram(binwidth = 30, position = "stack") +
  labs(title = "Distribution of Articles Over Time",
       x = "Publication Date",
       y = "Number of Articles") +
  theme_minimal() +
  theme(legend.position = "bottom")
```
```{r}
# 3. Word Cloud of Headlines
headline_words <- articles_df %>%
  unnest_tokens(word, headline) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE)

wordcloud(words = headline_words$word,
          freq = headline_words$n,
          max.words = 50,
          random.order = FALSE,
          colors = brewer.pal(8, "Dark2"))
```
```{r}
# 4. Sentiment Analysis
sentiment_scores <- articles_df %>%
  mutate(sentiment = get_sentiment(snippet)) %>%
  group_by(keyword) %>%
  summarise(avg_sentiment = mean(sentiment, na.rm = TRUE))

sentiment_plot <- ggplot(sentiment_scores, 
                        aes(x = reorder(keyword, avg_sentiment), 
                            y = avg_sentiment)) +
  geom_bar(stat = "identity", 
           aes(fill = avg_sentiment > 0)) +
  coord_flip() +
  labs(title = "Average Sentiment by Keyword",
       x = "Keyword",
       y = "Average Sentiment Score") +
  theme_minimal() +
  scale_fill_manual(values = c("red", "green"))
```
```{r}
# 5. Section Distribution
section_plot <- articles_df %>%
  count(section, sort = TRUE) %>%
  na.omit() %>%
  ggplot(aes(x = reorder(section, n), y = n)) +
  geom_bar(stat = "identity", fill = "darkgreen") +
  coord_flip() +
  labs(title = "Distribution of Articles by Section",
       x = "Section",
       y = "Number of Articles") +
  theme_minimal()

# Arrange plots in a grid
grid.arrange(
  keyword_counts, 
  timeline_plot, 
  sentiment_plot, 
  section_plot,
  ncol = 2
)
```