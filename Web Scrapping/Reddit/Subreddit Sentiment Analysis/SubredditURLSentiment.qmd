---
title: "Subreddit Data Scrapping(Data Cleaning)"
author: "Sagnik Chakravarty and Namit Shrivastava"
subtitle: "University of Maryland, College Park"
format: html
editor: visual
---

We have got the url's for the subreddit, the keyword that we were interested in are as follows:

-   **BEV:** Battery Electric Vehicle

-   **PHEV:** Plug in Hybrid Vehicle

-   **HEV:** Hybrid Electric Vehicle

-   Battery Electric Vehicle

-   Plug in Electric Vehicle

-   Hybrid Electric Vehicle

-   Environment

-   Battery

-   Fuel

-   Gas

-   Sustainability

-   Sustainable

-   Pollution

The choice of this keywords are from the fact that we are going to see within the sentiment which category of electric vehicle sentiment is swaying towards i.e (BEV, PHEV, HEV) and how are the peoples sentiment are towards each of the model type, and i also want to know what are the sentiment to EV are towards broader topics on environment, sustainability and pollution, also how better or worse the sentiment is towards topic as fuel or gas

# Loading all the lists

```{r}
library(readr)
teslamotors <- readRDS("Teslamotors_url.rds")
fuckcars <- readRDS("fuckcars_url.rds")
electricvehicles <- readRDS("electricvehicles.rds")
teslamodel3 <- readRDS("teslamodel3.rds")
rivian <- readRDS("Rivian.rds")
keywords <- c('BEV',
              'PHEV',
              'HEV',
              'Battery Electric Vehicle',
              'Plug in Hybrid Electric Vehicle',
              'Hybrid Electric Vehicle',
              'environment',
              'battery',
              'fuel',
              'gas',
              'sustainability',
              'sustainable',
              'pollution',
              'autonomous')
```

# Creating the necessary Function

First lets select the necessary columns we are not selecting [timestamp]{.smallcaps} and [subreddit]{.smallcaps} columns

## Converting to DF

```{r}
create_keyword_dataframe <- function(result_list){
  names(result_list) <- keywords
  df <- data.frame()
  for(i in names(result_list)){
    if(nrow(result_list[[i]])>0){
      temp_df <- result_list[[i]]
      temp_df$matched_keyword <- i
      df <- rbind(df, temp_df)
    }
  }
  df <- unique(df)
  
  final_df <- aggregate(
    matched_keyword ~ date_utc+ url+ text+ title+ comments,
    data = df,
    FUN = function(x) paste(unique(x), collapse = ",")
  )
  return(final_df)
}
```

Now lets clean the text data a bit for more readability

## Text Cleaning

```{r}
library(tidytext)
library(dplyr)
library(stringr)
clean_text_df <- function(x) {
  tk <- tibble(line = 1:length(x), text = x) 
  tk <- tk %>%
    unnest_tokens(word, text) %>%
    anti_join(stop_words, by = "word")
  cleaned_text <- tolower(str_c(tk$word, collapse = ' '))
  return(cleaned_text)
}
```

## Sentiment Analysis

We will be using all the sentiment analysis lexicon from tidytext that is bing, afinn, nrc, laughran. Since the data are internet data, the sentiment based on this lexicon would work great as they were used using crowd sourced or twitter data hence they would work great on data based on reddit

```{r}
# library(textdata)
# library(tidyr)
# 
# nrc <- get_sentiments('nrc')
# afinn <- get_sentiments('afinn')
# bing <- get_sentiments('bing')
#   
# get_sentiments <- function(x){
#   tk <- tibble(line = 1:length(x), text = x)
#   tk <- tk %>% 
#     unnest_tokens(word, text) %>%
#     inner_join(get_sentiments('nrc')) %>%
#     count(line, sentiment) %>%
#     pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
#     mutate(sentiment_nrc = positive - negative)
#   
#   return(tk)
# }
# 
# get_sentiments(teslamotors_df$cleaned_title[1])
```

# Teslamotors

```{r}
teslamotors_df <- create_keyword_dataframe(teslamotors)

teslamotors_df <- teslamotors_df %>% 
  rowwise() %>%
  mutate(cleaned_title = clean_text_df(title), 
         cleaned_text = clean_text_df(text)) %>%
  select(-title, -text) %>%
  ungroup()

teslamotors_df$date_utc <- as.Date(teslamotors_df$date_utc)

write_csv(teslamotors_df, 'teslamotors.csv')
```

# Fuckcars

```{r}
fuckcars_df <- create_keyword_dataframe(fuckcars)

fuckcars_df <- fuckcars_df %>% 
  rowwise() %>%
  mutate(cleaned_title = clean_text_df(title), 
         cleaned_text = clean_text_df(text)) %>%
  select(-title, -text) %>%
  ungroup()

fuckcars_df$date_utc <- as.Date(fuckcars_df$date_utc)
write_csv(fuckcars_df, 'fuckcars.csv')
```

# ElectricVehicles

```{r}
electricvehicles_df <- create_keyword_dataframe(electricvehicles)

electricvehicles_df <- electricvehicles_df %>% 
  rowwise() %>%
  mutate(cleaned_title = clean_text_df(title), 
         cleaned_text = clean_text_df(text)) %>%
  select(-title, -text) %>%
  ungroup()

electricvehicles_df$date_utc <- as.Date(electricvehicles_df$date_utc)

write_csv(electricvehicles_df, 'electric_vehicles.csv')
```

# Teslamodel3

```{r}
teslamodel3_df <- create_keyword_dataframe(teslamodel3)

teslamodel3_df <- teslamodel3_df %>% 
  rowwise() %>%
  mutate(cleaned_title = clean_text_df(title), 
         cleaned_text = clean_text_df(text)) %>%
  select(-title, -text) %>%
  ungroup()

teslamodel3_df$date_utc <- as.Date(teslamodel3_df$date_utc)

write_csv(teslamodel3_df, 'teslamdel3.csv')
```

# Rivian

```{r}
rivian_df <- create_keyword_dataframe(rivian)

rivian_df <- rivian_df %>% 
  rowwise() %>%
  mutate(cleaned_title = clean_text_df(title), 
         cleaned_text = clean_text_df(text)) %>%
  select(-title, -text) %>%
  ungroup()

rivian_df$date_utc <- as.Date(rivian_df$date_utc)
write_csv(rivian_df, 'rivian.csv')
```
